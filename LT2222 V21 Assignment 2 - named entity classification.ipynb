{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this assignment, you are going to build a classifier for named entities from the Groningen Meaning Bank corpus.  Named entity recognition (NER) takes noun phrases from a text and identifies whether they are persons, organizations, and so on.  You will be using the Groningen Meaning Bank named entity corpus available on mltgpu at `/scratch/lt2222-v21-resources/GMB_dataset.txt`.  In this version of the task, you will assume we know *that* something is a named entity, and instead use multi-class classification to identify its type.  So you will be doing named entity classification but *not* recognition.\n",
    "\n",
    "The data looks like this: \n",
    "\n",
    "```\n",
    "3996    182.0   Nicole  NNP     B-per\n",
    "3997    182.0   Ritchie NNP     I-per\n",
    "3998    182.0   is      VBZ     O\n",
    "3999    182.0   pregnant        JJ      O\n",
    "4000    182.0   .       .       O\n",
    "4001    183.0   Speaking        VBG     O\n",
    "4002    183.0   to      TO      O\n",
    "4003    183.0   ABC     NNP     B-org\n",
    "4004    183.0   News    NNP     I-org\n",
    "4005    183.0   interviewer     NN      O\n",
    "4006    183.0   Dianne  NNP     B-per\n",
    "4007    183.0   Sawyer  NNP     I-per\n",
    "4008    183.0   ,       ,       O\n",
    "4009    183.0   the     DT      O\n",
    "4010    183.0   25-year-old     JJ      O\n",
    "4011    183.0   co-star NN      O\n",
    "4012    183.0   of      IN      O\n",
    "4013    183.0   TV      NN      O\n",
    "4014    183.0   's      POS     O\n",
    "4015    183.0   The     DT      B-art\n",
    "4016    183.0   Simple  NNP     I-art\n",
    "4017    183.0   Life    NNP     I-art\n",
    "4018    183.0   said    VBD     O\n",
    "4019    183.0   she     PRP     O\n",
    "4020    183.0   is      VBZ     O\n",
    "4021    183.0   almost  RB      O\n",
    "4022    183.0   four    CD      O\n",
    "4023    183.0   months  NNS     O\n",
    "4024    183.0   along   IN      O\n",
    "4025    183.0   in      IN      O\n",
    "4026    183.0   her     PRP$    O\n",
    "4027    183.0   pregnancy       NN      O\n",
    "4028    183.0   .       .       O\n",
    "```\n",
    "\n",
    "The first column is the line number.  The second column is a sentence number (for some reason given as a float; ignore it).  The third column is the word.  The fourth column is a part of speech (POS) tag in Penn Treebank format.  The last column contains the named entity annotation. \n",
    "\n",
    "The annotation works like this.  Every `O` just means that the row does not represent a named entity.  `B-xyx` means the first word in a named entity with type `xyx`. `I-xyz` means the second and later words of an `xyz` entity, if there are any.  That means that every time there's a `B` or an `I`, there's a named entity.  \n",
    "\n",
    "The entity types in the corpus are `art`,\n",
    "`eve`,\n",
    "`geo`,\n",
    "`gpe`,\n",
    "`nat`,\n",
    "`org`,\n",
    "`per`,\n",
    "and `tim`\n",
    "\n",
    "Your task is the following.\n",
    "\n",
    "1. To preprocess the text (lowercase and lemmatize; punctuation can be preserved as it gets its own rows).\n",
    "\n",
    "2. To create instances from every from every identified named entity in the text with the type of the NE as the class, and a surrounding context of five words on either side as the features.  \n",
    "\n",
    "3. To generate vectors and split the instances into training and testing datasets at random.\n",
    "\n",
    "4. To train a support vector machine (via `sklearn.svm.LinearSVC`) for classifying the NERs.\n",
    "\n",
    "5. To evaluate the performance of the classifier.\n",
    "\n",
    "\n",
    "You will do this by modifying a separate file containing functions that will be called from this notebook as a module.  You can modify this notebook for testing purposes but please only submit the original.  You will document everything in Markdown in README.md and submit a GitHub repository URL.\n",
    "\n",
    "This assignment is due on **Tuesday, 2021 March 9 at 23:59**.  It has **25 points** and **7 bonus points**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import a2\n",
    "from sklearn.svm import LinearSVC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmbfile = open('/scratch/lt2222-v21-resources/GMB_dataset.txt', \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - preprocessing (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See step 1 above.  The data is coming to you as an unused file handle object.  You can return the data in any indexable form you like.  You can also choose to remove infrequent or uninformative words to reduce the size of the feature space. (Document this in README.md.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Line_No  Sentence_No          Word  POS    NER\n",
       "0         0            1      thousand  NNS      O\n",
       "1         1            1            of   IN      O\n",
       "2         2            1  demonstrator  NNS      O\n",
       "3         3            1          have  VBP      O\n",
       "4         4            1         march  VBN      O\n",
       "5         5            1       through   IN      O\n",
       "6         6            1        london  NNP  B-geo\n",
       "7         7            1            to   TO      O\n",
       "8         8            1       protest   VB      O\n",
       "9         9            1           the   DT      O\n",
       "10       10            1           war   NN      O\n",
       "11       11            1            in   IN      O\n",
       "12       12            1          iraq  NNP  B-geo\n",
       "13       13            1           and   CC      O\n",
       "14       14            1        demand   VB      O\n",
       "15       15            1           the   DT      O\n",
       "16       16            1    withdrawal   NN      O\n",
       "17       17            1            of   IN      O\n",
       "18       18            1       british   JJ  B-gpe\n",
       "19       19            1         troop  NNS      O"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Line_No</th>\n      <th>Sentence_No</th>\n      <th>Word</th>\n      <th>POS</th>\n      <th>NER</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>thousand</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n      <td>demonstrator</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1</td>\n      <td>have</td>\n      <td>VBP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1</td>\n      <td>march</td>\n      <td>VBN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>1</td>\n      <td>through</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>1</td>\n      <td>london</td>\n      <td>NNP</td>\n      <td>B-geo</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>1</td>\n      <td>to</td>\n      <td>TO</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>1</td>\n      <td>protest</td>\n      <td>VB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>1</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>1</td>\n      <td>war</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>1</td>\n      <td>in</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>1</td>\n      <td>iraq</td>\n      <td>NNP</td>\n      <td>B-geo</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>1</td>\n      <td>and</td>\n      <td>CC</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>1</td>\n      <td>demand</td>\n      <td>VB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>1</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>1</td>\n      <td>withdrawal</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>1</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>1</td>\n      <td>british</td>\n      <td>JJ</td>\n      <td>B-gpe</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>1</td>\n      <td>troop</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "\n",
    "inputdata = a2.preprocess(gmbfile)\n",
    "gmbfile.close()\n",
    "inputdata[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Creating instances (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do step 2 above.  You will create a collection of Instance objects.  Remember to consider the case where the NE is at the beginning of a sentence or at the end, or close to either (you can create a special start token for that).  You can also start counting from before the `B` end of the NE mention and after the last `I` of the NE mention. That means that the instances should include things before and after the named entity mention, but not the named entity text itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "instances = a2.create_instances(inputdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Class: gpe Features: ['<S5>', 'this', 'week', 'restart', 'part', 'the', 'conversion', 'process', 'at', '</S5>'],\n",
       " Class: geo Features: ['<S1>', '<S2>', '<S3>', '<S4>', '<S5>', '</S5>', '</S4>', '</S3>', '</S2>', '</S1>'],\n",
       " Class: gpe Features: ['<S5>', 'official', 'say', 'they', 'expect', 'get', 'access', 'to', 'sealed', 'sensitive'],\n",
       " Class: tim Features: ['<S2>', '<S3>', '<S4>', '<S5>', 'surveillance', 'begin', 'function', '</S5>', '</S4>', '</S3>'],\n",
       " Class: org Features: ['<S5>', 'surveillance', 'system', 'begin', 'function', '</S5>', '</S4>', '</S3>', '</S2>', '</S1>'],\n",
       " Class: org Features: ['<S2>', '<S3>', '<S4>', '<S5>', 'backing', 'threaten', 'to', 'refer', '</S5>', '</S4>'],\n",
       " Class: gpe Features: ['<S5>', 'backing', 'have', 'threaten', 'to', '</S5>', '</S4>', '</S3>', '</S2>', '</S1>'],\n",
       " Class: gpe Features: ['<S1>', '<S2>', '<S3>', '<S4>', '<S5>', 'which', 'could', 'impose', 'sanction', 'if'],\n",
       " Class: org Features: ['<S3>', '<S4>', '<S5>', 'which', 'could', 'sanction', 'if', 'it', 'find', '</S5>'],\n",
       " Class: gpe Features: ['<S1>', '<S2>', '<S3>', '<S4>', '<S5>', 'treaty', '</S5>', '</S4>', '</S3>', '</S2>'],\n",
       " Class: art Features: ['<S1>', '<S2>', '<S3>', '<S4>', '<S5>', '</S5>', '</S4>', '</S3>', '</S2>', '</S1>'],\n",
       " Class: gpe Features: ['<S1>', '<S2>', '<S3>', '<S4>', '<S5>', 'say', '</S5>', '</S4>', '</S3>', '</S2>'],\n",
       " Class: per Features: ['<S1>', '<S2>', '<S3>', '<S4>', '<S5>', '</S5>', '</S4>', '</S3>', '</S2>', '</S1>'],\n",
       " Class: tim Features: ['<S3>', '<S4>', '<S5>', 'incentive', 'aim', 'persuade', '</S5>', '</S4>', '</S3>', '</S2>'],\n",
       " Class: gpe Features: ['<S5>', 'incentive', 'aim', 'at', 'persuade', 'to', 'end', 'nuclear', 'fuel', 'program'],\n",
       " Class: gpe Features: ['<S5>', 'to', 'end', 'nuclear', 'fuel', 'be', 'an', 'insult', 'to', 'the'],\n",
       " Class: gpe Features: ['<S1>', '<S2>', '<S3>', '<S4>', '<S5>', '</S5>', '</S4>', '</S3>', '</S2>', '</S1>'],\n",
       " Class: gpe Features: ['<S2>', '<S3>', '<S4>', '<S5>', 'oil', 'be', 'kidnap', 'by', 'armed', 'militant'],\n",
       " Class: gpe Features: ['<S5>', 'oil', 'worker', 'be', 'kidnap', 'armed', 'militant', 'during', 'a', 'raid'],\n",
       " Class: geo Features: ['<S1>', '<S2>', '<S3>', '<S4>', '<S5>', '</S5>', '</S4>', '</S3>', '</S2>', '</S1>']]"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "instances[20:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Creating the table and splitting (10 points)\n",
    "\n",
    "Here you're going to write the functions that create a data table with \"document\" vectors representing each instance and split the table into training and testing sets and random with an 80%/20% train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Class         0         1         2         3         4         5  \\\n",
       "20   gpe  5.032928 -1.120715  0.375585  0.116922  0.145641 -0.487438   \n",
       "21   gpe  5.989315  0.056117 -0.157471 -0.094129 -0.125747 -0.019278   \n",
       "22   gpe  4.991326  0.047065 -0.132388 -0.079418 -0.106476 -0.016392   \n",
       "23   gpe  5.030752  0.568323  0.758935  0.168941  0.158547  0.022137   \n",
       "24   gpe  7.997703  0.133758 -0.194957 -0.166327 -0.280392 -0.060328   \n",
       "25   gpe  6.028335 -0.904722  0.224634  0.021182 -0.067715  0.884588   \n",
       "26   gpe  6.000123  0.074781 -0.239641 -0.181075 -0.329846 -0.087698   \n",
       "27   gpe  5.998953  0.072186 -0.226844 -0.164635 -0.280608 -0.063379   \n",
       "28   gpe  6.012878  0.124895 -0.685803  0.906508  0.261858  0.018889   \n",
       "29   gpe  6.008186  0.099747 -0.404621 -0.711291  0.869033  0.038004   \n",
       "30   per  5.032928 -1.120715  0.375585  0.116922  0.145641 -0.487438   \n",
       "31   per  7.001126  0.127837 -0.174950 -0.157143 -0.271199 -0.059313   \n",
       "32   per  3.999840  0.074140 -0.084181 -0.076430 -0.123005 -0.023412   \n",
       "33   per  9.986998  0.111728 -0.265114 -0.173148 -0.246684 -0.041562   \n",
       "34   per  4.033236  0.585164  0.844167  0.208181  0.214594  0.032334   \n",
       "35   per  4.002002  0.062706 -0.154021 -0.131447 -0.264422 -0.089293   \n",
       "36   per  7.992529  0.108977 -0.195620 -0.142891 -0.215504 -0.039051   \n",
       "37   per  6.028335 -0.904722  0.224634  0.021182 -0.067715  0.884588   \n",
       "38   per  6.000123  0.074781 -0.239641 -0.181075 -0.329846 -0.087698   \n",
       "39   per  5.998953  0.072186 -0.226844 -0.164635 -0.280608 -0.063379   \n",
       "\n",
       "           6         7         8  ...       290       291           292  \\\n",
       "20 -0.001267 -0.004255  0.001975  ...  0.000009 -0.000009 -1.015137e-05   \n",
       "21 -0.004521 -0.022386  0.034266  ...  0.000612  0.000910 -9.111536e-04   \n",
       "22 -0.003859 -0.019125  0.029345  ...  0.000151  0.000205 -2.200695e-04   \n",
       "23 -0.021922  0.016067 -0.048622  ...  0.000339  0.000669 -2.633947e-05   \n",
       "24  0.018610 -0.101562  0.285300  ... -0.001183 -0.012904 -7.305000e-03   \n",
       "25  0.006081  0.025655 -0.028096  ...  0.000014 -0.000012 -1.641171e-05   \n",
       "26 -0.062631 -0.550162 -0.670491  ...  0.000006  0.000009 -9.392105e-06   \n",
       "27 -0.026210 -0.155031  0.548019  ...  0.000007  0.000010 -1.051750e-05   \n",
       "28  0.002698  0.011721 -0.011259  ...  0.000010  0.000049  6.631323e-05   \n",
       "29  0.005342  0.023739 -0.027885  ... -0.000027 -0.000020 -8.107272e-06   \n",
       "30 -0.001267 -0.004255  0.001975  ...  0.000009 -0.000009 -1.015137e-05   \n",
       "31  0.017941 -0.100628  0.280964  ... -0.060842 -0.022279 -4.870743e-02   \n",
       "32 -0.008935 -0.038375  0.075469  ... -0.002663  0.024200  1.155087e-02   \n",
       "33  0.004177 -0.048153  0.090687  ... -0.000681  0.003771 -1.071133e-02   \n",
       "34 -0.010042  0.037359 -0.087074  ... -0.000988 -0.002914  3.195811e-04   \n",
       "35  1.242905  0.475836 -0.214955  ... -0.000204  0.000395  7.615173e-07   \n",
       "36 -0.008063 -0.058871  0.120463  ...  0.006844  0.004161  1.227664e-02   \n",
       "37  0.006081  0.025655 -0.028096  ...  0.000014 -0.000012 -1.641171e-05   \n",
       "38 -0.062631 -0.550162 -0.670491  ...  0.000006  0.000009 -9.392105e-06   \n",
       "39 -0.026210 -0.155031  0.548019  ...  0.000007  0.000010 -1.051750e-05   \n",
       "\n",
       "         293       294       295       296       297       298       299  \n",
       "20  0.000007  0.000007  0.000003 -0.000023 -0.000017 -0.000028 -0.000022  \n",
       "21  0.000999  0.000306  0.001713 -0.000620 -0.001243 -0.000801 -0.002649  \n",
       "22  0.000254  0.000057  0.000402 -0.000143 -0.000283 -0.000167 -0.000646  \n",
       "23  0.000183  0.000339 -0.000201 -0.000452  0.000070  0.000681 -0.000527  \n",
       "24  0.006051  0.000057  0.013404  0.017809  0.005645  0.003731 -0.002070  \n",
       "25  0.000012  0.000010  0.000008 -0.000035 -0.000027 -0.000042 -0.000037  \n",
       "26  0.000011  0.000002  0.000017 -0.000006 -0.000012 -0.000007 -0.000028  \n",
       "27  0.000012  0.000002  0.000019 -0.000007 -0.000013 -0.000008 -0.000031  \n",
       "28 -0.000010 -0.000027 -0.000048 -0.000019 -0.000101  0.000006  0.000013  \n",
       "29  0.000039  0.000059  0.000002 -0.000040 -0.000028 -0.000014  0.000037  \n",
       "30  0.000007  0.000007  0.000003 -0.000023 -0.000017 -0.000028 -0.000022  \n",
       "31  0.038879 -0.008080  0.040995 -0.005628 -0.006905  0.004094 -0.054264  \n",
       "32  0.007091  0.016080  0.000846  0.003861  0.003584  0.010507  0.023450  \n",
       "33 -0.000522  0.015049  0.001841 -0.002685  0.012983  0.002151 -0.001716  \n",
       "34  0.000149 -0.000139  0.002388  0.000927 -0.002212 -0.001683 -0.000098  \n",
       "35 -0.000598  0.000573  0.001196 -0.000951  0.000097 -0.001601 -0.000286  \n",
       "36 -0.014101 -0.013638  0.009373  0.023849 -0.012856  0.000614 -0.000412  \n",
       "37  0.000012  0.000010  0.000008 -0.000035 -0.000027 -0.000042 -0.000037  \n",
       "38  0.000011  0.000002  0.000017 -0.000006 -0.000012 -0.000007 -0.000028  \n",
       "39  0.000012  0.000002  0.000019 -0.000007 -0.000013 -0.000008 -0.000031  \n",
       "\n",
       "[20 rows x 301 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Class</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>...</th>\n      <th>290</th>\n      <th>291</th>\n      <th>292</th>\n      <th>293</th>\n      <th>294</th>\n      <th>295</th>\n      <th>296</th>\n      <th>297</th>\n      <th>298</th>\n      <th>299</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20</th>\n      <td>gpe</td>\n      <td>5.032928</td>\n      <td>-1.120715</td>\n      <td>0.375585</td>\n      <td>0.116922</td>\n      <td>0.145641</td>\n      <td>-0.487438</td>\n      <td>-0.001267</td>\n      <td>-0.004255</td>\n      <td>0.001975</td>\n      <td>...</td>\n      <td>0.000009</td>\n      <td>-0.000009</td>\n      <td>-1.015137e-05</td>\n      <td>0.000007</td>\n      <td>0.000007</td>\n      <td>0.000003</td>\n      <td>-0.000023</td>\n      <td>-0.000017</td>\n      <td>-0.000028</td>\n      <td>-0.000022</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>gpe</td>\n      <td>5.989315</td>\n      <td>0.056117</td>\n      <td>-0.157471</td>\n      <td>-0.094129</td>\n      <td>-0.125747</td>\n      <td>-0.019278</td>\n      <td>-0.004521</td>\n      <td>-0.022386</td>\n      <td>0.034266</td>\n      <td>...</td>\n      <td>0.000612</td>\n      <td>0.000910</td>\n      <td>-9.111536e-04</td>\n      <td>0.000999</td>\n      <td>0.000306</td>\n      <td>0.001713</td>\n      <td>-0.000620</td>\n      <td>-0.001243</td>\n      <td>-0.000801</td>\n      <td>-0.002649</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>gpe</td>\n      <td>4.991326</td>\n      <td>0.047065</td>\n      <td>-0.132388</td>\n      <td>-0.079418</td>\n      <td>-0.106476</td>\n      <td>-0.016392</td>\n      <td>-0.003859</td>\n      <td>-0.019125</td>\n      <td>0.029345</td>\n      <td>...</td>\n      <td>0.000151</td>\n      <td>0.000205</td>\n      <td>-2.200695e-04</td>\n      <td>0.000254</td>\n      <td>0.000057</td>\n      <td>0.000402</td>\n      <td>-0.000143</td>\n      <td>-0.000283</td>\n      <td>-0.000167</td>\n      <td>-0.000646</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>gpe</td>\n      <td>5.030752</td>\n      <td>0.568323</td>\n      <td>0.758935</td>\n      <td>0.168941</td>\n      <td>0.158547</td>\n      <td>0.022137</td>\n      <td>-0.021922</td>\n      <td>0.016067</td>\n      <td>-0.048622</td>\n      <td>...</td>\n      <td>0.000339</td>\n      <td>0.000669</td>\n      <td>-2.633947e-05</td>\n      <td>0.000183</td>\n      <td>0.000339</td>\n      <td>-0.000201</td>\n      <td>-0.000452</td>\n      <td>0.000070</td>\n      <td>0.000681</td>\n      <td>-0.000527</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>gpe</td>\n      <td>7.997703</td>\n      <td>0.133758</td>\n      <td>-0.194957</td>\n      <td>-0.166327</td>\n      <td>-0.280392</td>\n      <td>-0.060328</td>\n      <td>0.018610</td>\n      <td>-0.101562</td>\n      <td>0.285300</td>\n      <td>...</td>\n      <td>-0.001183</td>\n      <td>-0.012904</td>\n      <td>-7.305000e-03</td>\n      <td>0.006051</td>\n      <td>0.000057</td>\n      <td>0.013404</td>\n      <td>0.017809</td>\n      <td>0.005645</td>\n      <td>0.003731</td>\n      <td>-0.002070</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>gpe</td>\n      <td>6.028335</td>\n      <td>-0.904722</td>\n      <td>0.224634</td>\n      <td>0.021182</td>\n      <td>-0.067715</td>\n      <td>0.884588</td>\n      <td>0.006081</td>\n      <td>0.025655</td>\n      <td>-0.028096</td>\n      <td>...</td>\n      <td>0.000014</td>\n      <td>-0.000012</td>\n      <td>-1.641171e-05</td>\n      <td>0.000012</td>\n      <td>0.000010</td>\n      <td>0.000008</td>\n      <td>-0.000035</td>\n      <td>-0.000027</td>\n      <td>-0.000042</td>\n      <td>-0.000037</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>gpe</td>\n      <td>6.000123</td>\n      <td>0.074781</td>\n      <td>-0.239641</td>\n      <td>-0.181075</td>\n      <td>-0.329846</td>\n      <td>-0.087698</td>\n      <td>-0.062631</td>\n      <td>-0.550162</td>\n      <td>-0.670491</td>\n      <td>...</td>\n      <td>0.000006</td>\n      <td>0.000009</td>\n      <td>-9.392105e-06</td>\n      <td>0.000011</td>\n      <td>0.000002</td>\n      <td>0.000017</td>\n      <td>-0.000006</td>\n      <td>-0.000012</td>\n      <td>-0.000007</td>\n      <td>-0.000028</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>gpe</td>\n      <td>5.998953</td>\n      <td>0.072186</td>\n      <td>-0.226844</td>\n      <td>-0.164635</td>\n      <td>-0.280608</td>\n      <td>-0.063379</td>\n      <td>-0.026210</td>\n      <td>-0.155031</td>\n      <td>0.548019</td>\n      <td>...</td>\n      <td>0.000007</td>\n      <td>0.000010</td>\n      <td>-1.051750e-05</td>\n      <td>0.000012</td>\n      <td>0.000002</td>\n      <td>0.000019</td>\n      <td>-0.000007</td>\n      <td>-0.000013</td>\n      <td>-0.000008</td>\n      <td>-0.000031</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>gpe</td>\n      <td>6.012878</td>\n      <td>0.124895</td>\n      <td>-0.685803</td>\n      <td>0.906508</td>\n      <td>0.261858</td>\n      <td>0.018889</td>\n      <td>0.002698</td>\n      <td>0.011721</td>\n      <td>-0.011259</td>\n      <td>...</td>\n      <td>0.000010</td>\n      <td>0.000049</td>\n      <td>6.631323e-05</td>\n      <td>-0.000010</td>\n      <td>-0.000027</td>\n      <td>-0.000048</td>\n      <td>-0.000019</td>\n      <td>-0.000101</td>\n      <td>0.000006</td>\n      <td>0.000013</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>gpe</td>\n      <td>6.008186</td>\n      <td>0.099747</td>\n      <td>-0.404621</td>\n      <td>-0.711291</td>\n      <td>0.869033</td>\n      <td>0.038004</td>\n      <td>0.005342</td>\n      <td>0.023739</td>\n      <td>-0.027885</td>\n      <td>...</td>\n      <td>-0.000027</td>\n      <td>-0.000020</td>\n      <td>-8.107272e-06</td>\n      <td>0.000039</td>\n      <td>0.000059</td>\n      <td>0.000002</td>\n      <td>-0.000040</td>\n      <td>-0.000028</td>\n      <td>-0.000014</td>\n      <td>0.000037</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>per</td>\n      <td>5.032928</td>\n      <td>-1.120715</td>\n      <td>0.375585</td>\n      <td>0.116922</td>\n      <td>0.145641</td>\n      <td>-0.487438</td>\n      <td>-0.001267</td>\n      <td>-0.004255</td>\n      <td>0.001975</td>\n      <td>...</td>\n      <td>0.000009</td>\n      <td>-0.000009</td>\n      <td>-1.015137e-05</td>\n      <td>0.000007</td>\n      <td>0.000007</td>\n      <td>0.000003</td>\n      <td>-0.000023</td>\n      <td>-0.000017</td>\n      <td>-0.000028</td>\n      <td>-0.000022</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>per</td>\n      <td>7.001126</td>\n      <td>0.127837</td>\n      <td>-0.174950</td>\n      <td>-0.157143</td>\n      <td>-0.271199</td>\n      <td>-0.059313</td>\n      <td>0.017941</td>\n      <td>-0.100628</td>\n      <td>0.280964</td>\n      <td>...</td>\n      <td>-0.060842</td>\n      <td>-0.022279</td>\n      <td>-4.870743e-02</td>\n      <td>0.038879</td>\n      <td>-0.008080</td>\n      <td>0.040995</td>\n      <td>-0.005628</td>\n      <td>-0.006905</td>\n      <td>0.004094</td>\n      <td>-0.054264</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>per</td>\n      <td>3.999840</td>\n      <td>0.074140</td>\n      <td>-0.084181</td>\n      <td>-0.076430</td>\n      <td>-0.123005</td>\n      <td>-0.023412</td>\n      <td>-0.008935</td>\n      <td>-0.038375</td>\n      <td>0.075469</td>\n      <td>...</td>\n      <td>-0.002663</td>\n      <td>0.024200</td>\n      <td>1.155087e-02</td>\n      <td>0.007091</td>\n      <td>0.016080</td>\n      <td>0.000846</td>\n      <td>0.003861</td>\n      <td>0.003584</td>\n      <td>0.010507</td>\n      <td>0.023450</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>per</td>\n      <td>9.986998</td>\n      <td>0.111728</td>\n      <td>-0.265114</td>\n      <td>-0.173148</td>\n      <td>-0.246684</td>\n      <td>-0.041562</td>\n      <td>0.004177</td>\n      <td>-0.048153</td>\n      <td>0.090687</td>\n      <td>...</td>\n      <td>-0.000681</td>\n      <td>0.003771</td>\n      <td>-1.071133e-02</td>\n      <td>-0.000522</td>\n      <td>0.015049</td>\n      <td>0.001841</td>\n      <td>-0.002685</td>\n      <td>0.012983</td>\n      <td>0.002151</td>\n      <td>-0.001716</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>per</td>\n      <td>4.033236</td>\n      <td>0.585164</td>\n      <td>0.844167</td>\n      <td>0.208181</td>\n      <td>0.214594</td>\n      <td>0.032334</td>\n      <td>-0.010042</td>\n      <td>0.037359</td>\n      <td>-0.087074</td>\n      <td>...</td>\n      <td>-0.000988</td>\n      <td>-0.002914</td>\n      <td>3.195811e-04</td>\n      <td>0.000149</td>\n      <td>-0.000139</td>\n      <td>0.002388</td>\n      <td>0.000927</td>\n      <td>-0.002212</td>\n      <td>-0.001683</td>\n      <td>-0.000098</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>per</td>\n      <td>4.002002</td>\n      <td>0.062706</td>\n      <td>-0.154021</td>\n      <td>-0.131447</td>\n      <td>-0.264422</td>\n      <td>-0.089293</td>\n      <td>1.242905</td>\n      <td>0.475836</td>\n      <td>-0.214955</td>\n      <td>...</td>\n      <td>-0.000204</td>\n      <td>0.000395</td>\n      <td>7.615173e-07</td>\n      <td>-0.000598</td>\n      <td>0.000573</td>\n      <td>0.001196</td>\n      <td>-0.000951</td>\n      <td>0.000097</td>\n      <td>-0.001601</td>\n      <td>-0.000286</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>per</td>\n      <td>7.992529</td>\n      <td>0.108977</td>\n      <td>-0.195620</td>\n      <td>-0.142891</td>\n      <td>-0.215504</td>\n      <td>-0.039051</td>\n      <td>-0.008063</td>\n      <td>-0.058871</td>\n      <td>0.120463</td>\n      <td>...</td>\n      <td>0.006844</td>\n      <td>0.004161</td>\n      <td>1.227664e-02</td>\n      <td>-0.014101</td>\n      <td>-0.013638</td>\n      <td>0.009373</td>\n      <td>0.023849</td>\n      <td>-0.012856</td>\n      <td>0.000614</td>\n      <td>-0.000412</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>per</td>\n      <td>6.028335</td>\n      <td>-0.904722</td>\n      <td>0.224634</td>\n      <td>0.021182</td>\n      <td>-0.067715</td>\n      <td>0.884588</td>\n      <td>0.006081</td>\n      <td>0.025655</td>\n      <td>-0.028096</td>\n      <td>...</td>\n      <td>0.000014</td>\n      <td>-0.000012</td>\n      <td>-1.641171e-05</td>\n      <td>0.000012</td>\n      <td>0.000010</td>\n      <td>0.000008</td>\n      <td>-0.000035</td>\n      <td>-0.000027</td>\n      <td>-0.000042</td>\n      <td>-0.000037</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>per</td>\n      <td>6.000123</td>\n      <td>0.074781</td>\n      <td>-0.239641</td>\n      <td>-0.181075</td>\n      <td>-0.329846</td>\n      <td>-0.087698</td>\n      <td>-0.062631</td>\n      <td>-0.550162</td>\n      <td>-0.670491</td>\n      <td>...</td>\n      <td>0.000006</td>\n      <td>0.000009</td>\n      <td>-9.392105e-06</td>\n      <td>0.000011</td>\n      <td>0.000002</td>\n      <td>0.000017</td>\n      <td>-0.000006</td>\n      <td>-0.000012</td>\n      <td>-0.000007</td>\n      <td>-0.000028</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>per</td>\n      <td>5.998953</td>\n      <td>0.072186</td>\n      <td>-0.226844</td>\n      <td>-0.164635</td>\n      <td>-0.280608</td>\n      <td>-0.063379</td>\n      <td>-0.026210</td>\n      <td>-0.155031</td>\n      <td>0.548019</td>\n      <td>...</td>\n      <td>0.000007</td>\n      <td>0.000010</td>\n      <td>-1.051750e-05</td>\n      <td>0.000012</td>\n      <td>0.000002</td>\n      <td>0.000019</td>\n      <td>-0.000007</td>\n      <td>-0.000013</td>\n      <td>-0.000008</td>\n      <td>-0.000031</td>\n    </tr>\n  </tbody>\n</table>\n<p>20 rows × 301 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "\n",
    "bigdf = a2.create_table(instances)\n",
    "bigdf[20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-67-072b14b1194a>, line 3)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-67-072b14b1194a>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    X and y mean feature matrix and class respectively.\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y, test_X, test_y = a2.ttsplit(bigdf)\n",
    "\n",
    "# X and y mean feature matrix and class respectively.\n",
    "train_X, train_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_y) / (len(test_y) + len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_X) / (len(test_X) + len(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Training the model (0 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part you won't do yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC()\n",
    "model.fit(train_X, train_y)\n",
    "train_predictions = model.predict(train_X)\n",
    "test_predictions = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 - Evaluation (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate for yourself what a \"confusion matrix\".  Then implement a function that takes the data and produces a confusion matrix in any readable form that allows us to compare the performance of the model by class.  "
   ]
  },
  {
   "source": [
    "a2.confusion_matrix(test_y, test_predictions)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2.confusion_matrix(train_y, train_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the matrix and describe your observations in README.md.  In particular, what do you notice about the predictions on the training data compared to those on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Part A - Error analysis (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the weakest-performing classes in the confusion matrix (or any, if they all perform poorly to the same extent).  Find some examples in the test data on which the classifier classified incorrectly for those classes.  What do you think is the reason why those are hard?  Consider linguistic factors and statistical factors, if applicable.  Write your answer in README.md."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Part B - Expanding the feature space (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the entire process above, but incorporate part-of-speech tag information into the feature vectors.  It's your choice as to how to do this, but document it in README.md.  Your new process should run from the single call below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2.bonusb('/scratch/lt2222-v21-resources/GMB_dataset.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}